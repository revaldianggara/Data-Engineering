{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPTAeiZykNcIqGdSy3PDDDQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Python environment libs"],"metadata":{"id":"L7M9O6sQ2hBZ"}},{"cell_type":"code","source":["!pip install pandas numpy\n","!pip install Faker"],"metadata":{"id":"PP0JF75k2pTA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Initial Tables Creation\n","### Copy CSV file into the container\n","`docker cp /home/user/random_dataset.csv postgres_container:/tmp/random_dataset.csv`\n","\n","### Connect to PostgreSQL\n","`docker exec -it postgres_container psql -U postgres -d your_database`\n","\n","### Once in psql\n","```\n","CREATE TABLE sales_data (\n","    date TIMESTAMP,\n","    name VARCHAR(50),\n","    market_area VARCHAR(100),\n","    number_of_sales INTEGER,\n","    pricing_unit INTEGER\n",");\n","```\n","\n","`\\copy sales_data FROM '/tmp/random_dataset.csv' WITH CSV HEADER;`"],"metadata":{"id":"i4R7ls1u4yhh"}},{"cell_type":"markdown","source":["## Python Data Mock-up / Generator"],"metadata":{"id":"v5c1TDj12RJy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"rR6M48Ua2FA4"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import random\n","from faker import Faker\n","from datetime import datetime, timedelta\n","from loguru import logger as log\n","\n","# Initialize Faker\n","fake = Faker(\"id_ID\")\n","\n","# Set the range for datetime\n","start_date = datetime(2023, 1, 1)\n","end_date = datetime(2024, 1, 1)\n","\n","\n","# Function to generate a random datetime between a given range\n","def random_date(start, end):\n","    return start + timedelta(\n","        seconds=np.random.randint(0, int((end - start).total_seconds()))\n","    )\n","\n","\n","# Function to generate each row\n","def generateSalesRow(names: list, prices: list):\n","    return {\n","        \"date\": random_date(start_date, end_date),\n","        \"name\": random.choice(names),\n","        \"market_area\": fake.administrative_unit(),\n","        \"number_of_sales\": fake.random_int(min=1, max=75),\n","        \"pricing_unit\": random.choice(prices),\n","    }\n","\n","\n","# Function to generate whole dataset\n","def generateSales(num: int):\n","    \"\"\"\n","    param :\n","    - num = nummber of dataset\n","    \"\"\"\n","    try:\n","        sales_list = [\n","            \"Diah\",\n","            \"Wahyu\",\n","            \"Lisa\",\n","            \"Anton\",\n","            \"Malik\",\n","            \"Riana\",\n","            \"Rafi\",\n","            \"Bela\",\n","            \"Budi\",\n","        ]\n","        pricing_units = [50000, 100000, 150000]\n","\n","        log.info(\"Flow - Generating Data Rows\")\n","        generated_data = [\n","            generateSalesRow(names=sales_list, prices=pricing_units) for _ in range(num)\n","        ]\n","\n","        log.info(\"Flow - Saving dataframe into csv\")\n","        generated_dataframe = pd.DataFrame(generated_data)\n","        generated_dataframe.to_csv(\"sales_generated.csv\", index=False)\n","    except Exception as e:\n","        log.error(f\"Flow error - error occured as {e}\")\n","\n","\n","if __name__ == \"__main__\":\n","    \"\"\"\n","    All entry point\n","    \"\"\"\n","    import argparse\n","\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument(\"-n\", \"--numbers\", help=\"Numbers of data to generate\", type=int)\n","    args = parser.parse_args()\n","\n","    if args.numbers:\n","        generateSales(num=args.numbers)\n","    else:\n","        log.error(\"Specify numbers\")\n"]},{"cell_type":"markdown","source":["## Export data to parquet"],"metadata":{"id":"CHaPanR02bMw"}},{"cell_type":"code","source":["!pip install psycopg2-binary\n","!pip install sqlalchemy, pyarrrow"],"metadata":{"id":"TpMXiWDu2f4T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import pyarrow as pa\n","import pyarrow.parquet as pq\n","from sqlalchemy import create_engine\n","from loguru import logger as log\n","\n","# Database connection parameters\n","db_params = {\n","    \"dbname\": \"postgres\",\n","    \"user\": \"postgres\",\n","    \"password\": \"password\",\n","    \"host\": \"localhost\",\n","    \"port\": \"5432\",\n","}\n","\n","# Create SQLAlchemy engine\n","engine = create_engine(\n","    f\"postgresql://{db_params['user']}:{db_params['password']}@{db_params['host']}:{db_params['port']}/{db_params['dbname']}\"\n",")\n","\n","# SQL query to fetch data\n","query = \"SELECT * FROM sales_data WHERE name = 'Budi'\"\n","\n","try:\n","    # Read data into a pandas DataFrame\n","    log.info(\"Flow - Connect and Fetch through DB\")\n","    with engine.connect() as conn:\n","        df = pd.read_sql_query(query, conn)\n","\n","    print(f\"DataFrame shape: {df.shape}\")\n","    print(df.head())\n","\n","    log.info(\"Flow - Converting to Parquet\")\n","    # Convert the pandas DataFrame to a PyArrow Table\n","    table = pa.Table.from_pandas(df)\n","\n","    # Write the PyArrow Table to a Parquet file\n","    pq.write_table(table, \"sales_data.parquet\")\n","\n","    log.info(\"Flow - Parquet Exported\")\n","except Exception as e:\n","    log.error(f\"Flow error - occured as {e}\")\n"],"metadata":{"id":"l4cSXnNb9cS5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Ingest via API"],"metadata":{"id":"JkPckMiC6Qjp"}},{"cell_type":"code","source":["!pip install pokebase\n","!pip install sqlalchemy"],"metadata":{"id":"NRNeCa0Q6kEv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pokebase as pb\n","from sqlalchemy import create_engine, text\n","from loguru import logger as log\n","\n","# Database connection parameters\n","db_params = {\n","    'dbname': 'postgres',\n","    'user': 'postgres',\n","    'password': 'password',\n","    'host': 'localhost',\n","    'port': '5432'\n","}\n","\n","# Create SQLAlchemy engine\n","engine = create_engine(f\"postgresql://{db_params['user']}:{db_params['password']}@{db_params['host']}:{db_params['port']}/{db_params['dbname']}\")\n","\n","# Function to insert a Pokemon into the database\n","def insert_pokemon(pokemon):\n","    query = text(\"\"\"\n","    INSERT INTO pokemon (id, name, height, weight, base_experience, type)\n","    VALUES (:id, :name, :height, :weight, :base_experience, :type)\n","    ON CONFLICT (id) DO UPDATE SET\n","        name = :name,\n","        height = :height,\n","        weight = :weight,\n","        base_experience = :base_experience,\n","        type = :type\n","    \"\"\")\n","\n","    with engine.connect() as conn:\n","        conn.execute(query, {\n","            'id': pokemon.id,\n","            'name': pokemon.name,\n","            'height': pokemon.height,\n","            'weight': pokemon.weight,\n","            'base_experience': pokemon.base_experience,\n","            'type': pokemon.types[0].type.name if pokemon.types else 'Unknown'\n","        })\n","        conn.commit()\n","\n","# Fetch and insert Pokemon data\n","def fetch_and_insert_pokemon(start_id, end_id):\n","    for pokemon_id in range(start_id, end_id + 1):\n","        try:\n","            pokemon = pb.pokemon(pokemon_id)\n","            insert_pokemon(pokemon)\n","            log.info(f\"Inserted Pokemon: {pokemon.name}\")\n","        except Exception as e:\n","            log.warning(f\"Error fetching Pokemon with ID {pokemon_id}: {e}\")\n","\n","if __name__ == \"__main__\":\n","    \"\"\"\n","    Main Entry Point\n","    \"\"\"\n","    fetch_and_insert_pokemon(1, 20)  # Fetch and insert first 20 Pokemon\n","\n","\"\"\"\n","CREATE TABLE pokemon (\n","    id INTEGER PRIMARY KEY,\n","    name VARCHAR(100),\n","    height INTEGER,\n","    weight INTEGER,\n","    base_experience INTEGER,\n","    type VARCHAR(50)\n",");\n","\"\"\""],"metadata":{"id":"3v4-njqo6QQs"},"execution_count":null,"outputs":[]}]}