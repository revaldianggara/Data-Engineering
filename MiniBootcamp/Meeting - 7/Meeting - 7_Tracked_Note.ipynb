{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN864rsWHDzA2u0LOxv+cg2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## CLICKHOUSE QUERY\n","\n","creating the view to be consumed by analytics app"],"metadata":{"id":"Nwb1uEl-m10w"}},{"cell_type":"code","source":["%%sql\n","-- CREATE VIEW\n","\n","CREATE VIEW sales_data_view\n","AS\n","SELECT\n","`date`,\n","name,\n","market_area,\n","toInt32(number_of_sales) as number_of_sales,\n","pricing_unit,\n","number_of_sales * pricing_unit as revenue,\n","toDateTime64(insert_time_clickhouse, 3, 'Asia/Jakarta') as insert_time_clickhouse,\n","toDateTime64(now(), 3 , 'Asia/Jakarta') as source_collected\n","FROM `default`.sales_data;"],"metadata":{"id":"fKDpbEfjm1A9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%sql\n","-- CORRECTION FOR BASE, KAFKA QUEUE AND MV\n","-- BASE\n","CREATE TABLE default.sales_data\n","(\n","    `date` Datetime,\n","    `name` String,\n","    `market_area` String,\n","    `number_of_sales` UInt32,\n","    `pricing_unit` Float64,\n","    `insert_time_clickhouse` SimpleAggregateFunction(max,\n"," DateTime('Asia/Jakarta')) DEFAULT now()\n",")\n","ENGINE = ReplacingMergeTree\n","PARTITION BY name\n","ORDER BY (date,\n"," name,\n"," market_area)\n","SETTINGS index_granularity = 8192;\n","\n","--KAFKA QUEUE\n","CREATE TABLE default.sales_data_queue\n","(\n","    `date` UInt64,\n","    `name` String,\n","    `market_area` String,\n","    `number_of_sales` Int32,\n","    `pricing_unit` Float64\n",")\n","ENGINE = Kafka\n","SETTINGS kafka_broker_list = 'stack-kafka-kafka-1:9092',\n"," kafka_topic_list = 'etl.public.sales_data',\n"," kafka_group_name = 'test-1',\n"," kafka_format = 'JSONEachRow';\n","\n","-- MV\n","CREATE MATERIALIZED VIEW default.sales_data_queue_mv TO default.sales_data\n","AS\n","SELECT\n","    toDateTime(`date` / 1000000) as date,\n","    name,\n","    market_area,\n","    number_of_sales,\n","    pricing_unit\n","FROM default.sales_data_queue;"],"metadata":{"id":"QPVwKVPK632l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## STREAMLIT SAMPLE DASHBOARD\n","save as app.py and run using streamlit command\n","\n","`streamlit run app.py`"],"metadata":{"id":"21leo6cwsxTx"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fd_6fSpamUm-"},"outputs":[],"source":["!pip install streamlit --no-cache-dir\n","!pip install clickhouse-sqlalchemy --no-cache-dir"]},{"cell_type":"code","source":["import streamlit as st\n","import pandas as pd\n","from sqlalchemy import create_engine\n","from sqlalchemy.orm import sessionmaker\n","from datetime import datetime\n","import time\n","#\n","\n","try:\n","    conn_str = 'clickhouse://default:password@localhost:18123/default'\n","    engine = create_engine(conn_str)\n","    session = sessionmaker(bind=engine)()\n","except Exception as e:\n","    print(\"Error while connectint to Clickhoust \" + str(e))\n","\n","\n","st.set_page_config(layout=\"wide\")\n","st.title(\"Sales Data Analytics Real-Time ▁ ▂ ▃ ▄ ▅ ▆ █\")\n","\n","now = datetime.now()\n","dt_string = now.strftime(\"%d %B %Y %H:%M:%S\")\n","st.write(f\"Last update: {dt_string}\")\n","\n","if not \"sleep_time\" in st.session_state:\n","    st.session_state.sleep_time = 5\n","\n","if not \"auto_refresh\" in st.session_state:\n","    st.session_state.auto_refresh = True\n","\n","#\n","mapping = {\n","    \"1 hour\": {\"period\": \"60\", \"granularity\": \"minute\", \"raw\": 60},\n","    \"30 minutes\": {\"period\": \"30\", \"granularity\": \"minute\", \"raw\": 30},\n","    \"10 minutes\": {\"period\": \"10\", \"granularity\": \"minute\", \"raw\": 10},\n","    \"5 minutes\": {\"period\": \"5\", \"granularity\": \"minute\", \"raw\": 5}\n","}\n","\n","with st.expander(\"Configure Dashboard\", expanded=True):\n","    left, right = st.columns(2)\n","\n","    with left:\n","        auto_refresh = st.checkbox('Auto Refresh?', st.session_state.auto_refresh)\n","\n","        if auto_refresh:\n","            number = st.number_input('Refresh rate in seconds', value=st.session_state.sleep_time)\n","            st.session_state.sleep_time = number\n","\n","    with right:\n","            time_ago = st.radio(\"Time period to cover\", mapping.keys(), horizontal=True, key=\"time_ago\")\n","\n","\n","\n","st.header(\"Live Kafka Streaming Sales Data ...\" )\n","\n","minute = mapping[time_ago][\"period\"]\n","print(str(minute))\n","query = f\"\"\"select\n","date,\n","name,\n","market_area,\n","number_of_sales,\n","revenue\n","from `default`.sales_data_view\n","where source_collected >=  insert_time_clickhouse -  INTERVAL {minute} MINUTE ;\"\"\"\n","\n","df = pd.read_sql(query, engine)\n","df.style.format('{:,}')\n","\n","metric1, metric2 = st.columns(2)\n","\n","metric1.metric(\n","    label=\"Total Number of Deals\",\n","    value=(df['number_of_sales'].sum()),\n",")\n","\n","metric2.metric(\n","    label=\"Sales Revenue\",\n","    value=(df['revenue'].sum()),\n",")\n","\n","#\n","st.header(f\"Incoming data completion since last {minute} minutes...\" )\n","#\n","st.line_chart(data = df, x= \"date\", y = \"number_of_sales\")\n","#\n","data_1, data_2 = st.columns(2)\n","data_1.markdown('## Number of Member Deals')\n","data_1.dataframe(df.groupby(['name'])['number_of_sales'].sum())\n","\n","data_2.markdown('## Number of Area Deals')\n","data_2.dataframe(df.groupby(['market_area'])['number_of_sales'].sum())\n","#\n","if auto_refresh:\n","    time.sleep(number)\n","    st.rerun()\n"],"metadata":{"id":"RvyqrNksmkXB"},"execution_count":null,"outputs":[]}]}